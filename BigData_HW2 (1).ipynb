{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BigData_HW2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gngg7x58pKUI","executionInfo":{"status":"ok","timestamp":1634716577409,"user_tz":300,"elapsed":122,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"c22709d0-d7a5-4ad1-baf1-5ef3196109c4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8-SU55D7znM","executionInfo":{"status":"ok","timestamp":1634716577666,"user_tz":300,"elapsed":140,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"ccdb6c3d-c31e-47a1-be71-f5936063ada7"},"source":["%cd /content/drive/My Drive/IDS 561/HW 2"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/IDS 561/HW 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"RVEP31aOWPOv"},"source":["Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java."]},{"cell_type":"code","metadata":{"id":"WHPiwBy97zzx","executionInfo":{"status":"ok","timestamp":1634716579549,"user_tz":300,"elapsed":1886,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WI7B08YtM8hJ"},"source":["# Get Spark installer (check the path on spark.apache.org)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XITPv9ZM7z-T","executionInfo":{"status":"ok","timestamp":1634716584577,"user_tz":300,"elapsed":5031,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"22b57085-9fed-447a-8723-6b4e941ae5e2"},"source":["!wget -v https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-10-20 07:57:23--  https://dlcdn.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n","Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n","Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 228834641 (218M) [application/x-gzip]\n","Saving to: ‘spark-3.1.2-bin-hadoop3.2.tgz.2’\n","\n","spark-3.1.2-bin-had 100%[===================>] 218.23M  45.4MB/s    in 4.8s    \n","\n","2021-10-20 07:57:28 (45.4 MB/s) - ‘spark-3.1.2-bin-hadoop3.2.tgz.2’ saved [228834641/228834641]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"Me2_9uto70IZ","executionInfo":{"status":"ok","timestamp":1634716584578,"user_tz":300,"elapsed":10,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":[""],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hvRiLqKINwkt"},"source":["# Check if the file is copied"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVKgCJi470SK","executionInfo":{"status":"ok","timestamp":1634718535909,"user_tz":300,"elapsed":321,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"5f11c18a-ea84-4a5c-9f0e-b018540b6086"},"source":["!ls"],"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":[" Amazon_Responded_Oct05.csv\t   spark-3.1.2-bin-hadoop3.2\n"," BigData_HW2.ipynb\t\t   spark-3.1.2-bin-hadoop3.2.tgz\n"," find_text.csv\t\t\t   spark-3.1.2-bin-hadoop3.2.tgz.1\n","'IDS 561  Homework 2 (1).docx'\t   spark-3.1.2-bin-hadoop3.2.tgz.2\n"," spark-3.0.0-bin-hadoop3.2\t   task2output.csv\n"," spark-3.0.0-bin-hadoop3.2.tgz\t   twitterhw2.csv\n"," spark-3.0.0-bin-hadoop3.2.tgz.1\n"]}]},{"cell_type":"code","metadata":{"id":"5a15Zi6Tp9T-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634716584872,"user_tz":300,"elapsed":146,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"9cd02b70-6f74-4d24-99bb-42ac4dfd0fae"},"source":["!pwd"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/IDS 561/HW 2\n"]}]},{"cell_type":"markdown","metadata":{"id":"ei9SqRpZOKpl"},"source":["# Untar the Spark installer"]},{"cell_type":"code","metadata":{"id":"_PJoZWXJp_XK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634716623646,"user_tz":300,"elapsed":38778,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"45d98451-5833-4a37-cb39-5729a9d5f77e"},"source":["!tar -xvf spark-3.1.2-bin-hadoop3.2.tgz"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["spark-3.1.2-bin-hadoop3.2/\n","spark-3.1.2-bin-hadoop3.2/R/\n","spark-3.1.2-bin-hadoop3.2/R/lib/\n","spark-3.1.2-bin-hadoop3.2/R/lib/sparkr.zip\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/worker/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/worker/worker.R\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/worker/daemon.R\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/tests/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/tests/testthat/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/tests/testthat/test_basic.R\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/profile/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/profile/shell.R\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/profile/general.R\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.html\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/sparkr-vignettes.R\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/doc/index.html\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/SparkR\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdx\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/R/SparkR.rdb\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/features.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/package.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/nsInfo.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/vignette.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/Rd.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/links.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/Meta/hsearch.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/DESCRIPTION\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/NAMESPACE\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/html/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/html/R.css\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/html/00Index.html\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/INDEX\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/aliases.rds\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/AnIndex\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdx\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/SparkR.rdb\n","spark-3.1.2-bin-hadoop3.2/R/lib/SparkR/help/paths.rds\n","spark-3.1.2-bin-hadoop3.2/sbin/\n","spark-3.1.2-bin-hadoop3.2/sbin/workers.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-workers.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-worker.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-thriftserver.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-slaves.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-slave.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-mesos-shuffle-service.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-mesos-dispatcher.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-master.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-history-server.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/stop-all.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-workers.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-worker.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-thriftserver.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-slaves.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-slave.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-mesos-shuffle-service.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-mesos-dispatcher.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-master.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-history-server.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/start-all.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/spark-daemons.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/spark-daemon.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/slaves.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/decommission-worker.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/decommission-slave.sh\n","spark-3.1.2-bin-hadoop3.2/sbin/spark-config.sh\n","spark-3.1.2-bin-hadoop3.2/python/\n","spark-3.1.2-bin-hadoop3.2/python/dist/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/SOURCES.txt\n","spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/top_level.txt\n","spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/requires.txt\n","spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/dependency_links.txt\n","spark-3.1.2-bin-hadoop3.2/python/pyspark.egg-info/PKG-INFO\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/python/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/python/pyspark/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/python/pyspark/shell.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/__pycache__/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/__pycache__/install.cpython-38.pyc\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/evaluation.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/common.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/common.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/clustering.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/classification.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/_typing.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/util.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/util.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tree.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tree.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_util.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_streaming_algorithms.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_stat.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_feature.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_algorithms.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/tests/test_linalg.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/regression.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/clustering.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/classification.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/KernelDensity.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/test.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/test.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/distribution.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/stat/_statistics.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/regression.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/recommendation.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/recommendation.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/random.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/random.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/linalg/distributed.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/fpm.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/fpm.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/feature.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/feature.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/mllib/evaluation.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/wrapper.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/wrapper.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/util.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/util.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tree.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_wrapper.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_util.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_stat.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_pipeline.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_persistence.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_linalg.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_image.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_feature.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_algorithms.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_tuning.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_training_summary.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_param.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_evaluation.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tests/test_base.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/stat.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/stat.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/regression.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/recommendation.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/pipeline.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/pipeline.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/shared.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/shared.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/_shared_params_code_gen.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/param/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/linalg/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/linalg/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/image.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/image.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/functions.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/fpm.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/feature.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/evaluation.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/common.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/common.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/clustering.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/classification.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/base.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/_typing.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tuning.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tuning.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/tree.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/regression.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/recommendation.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/functions.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/fpm.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/feature.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/evaluation.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/clustering.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/classification.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/ml/base.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/join.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/java_gateway.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/install.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/find_spark_home.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/files.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/files.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/daemon.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/context.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/context.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/conf.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/conf.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/compat.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle_fast.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/cloudpickle.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/cloudpickle/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/broadcast.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/broadcast.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/accumulators.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/accumulators.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/_typing.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/_globals.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/window.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/window.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/utils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/udf.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/types.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/types.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_utils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_udf.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_types.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_streaming.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_session.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_serde.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_readwriter.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_window.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_typehints.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_scalar.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf_grouped_agg.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_udf.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_map.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_cogrouped_map.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_datasources.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_context.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_conf.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_catalog.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_pandas_grouped_map.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_group.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_functions.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_dataframe.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_column.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/tests/test_arrow.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/streaming.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/session.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/readwriter.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/utils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/typehints.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/serializers.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/map_ops.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/group_ops.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/functions.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/functions.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/_typing/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/types.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/group.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/group.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/dataframe.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/context.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/conf.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/conf.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/column.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/catalog.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/functions.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/avro/functions.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/_typing.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/__init__.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/udf.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/streaming.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/session.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/readwriter.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/functions.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/functions.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/dataframe.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/context.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/column.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/catalog.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/shuffle.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/shell.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/serializers.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resultiterable.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resultiterable.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/tests/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/tests/test_resources.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/tests/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/requests.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/requests.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/information.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/information.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/profile.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/resource/profile.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/rddsampler.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/rdd.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/py.typed\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/profiler.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/profiler.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/worker.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/version.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/taskcontext.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/rdd.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/version.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/util.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/traceback_utils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_worker.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_util.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_taskcontext.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_shuffle.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_serializers.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_readwrite.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_rddbarrier.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_rdd.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_profiler.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_pin_thread.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_join.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_install_spark.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_daemon.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_context.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_conf.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_broadcast.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/test_appsubmit.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/tests/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/streamingutils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/sqlutils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/mlutils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/mllibutils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/testing/utils.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/taskcontext.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/util.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_listener.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_kinesis.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_dstream.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/test_context.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/tests/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/listener.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/listener.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/kinesis.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/kinesis.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/dstream.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/context.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/context.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/__init__.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/streaming/dstream.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/storagelevel.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/storagelevel.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/status.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/status.py\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/statcounter.pyi\n","spark-3.1.2-bin-hadoop3.2/python/pyspark/statcounter.py\n","spark-3.1.2-bin-hadoop3.2/python/pylintrc\n","spark-3.1.2-bin-hadoop3.2/python/lib/\n","spark-3.1.2-bin-hadoop3.2/python/lib/pyspark.zip\n","spark-3.1.2-bin-hadoop3.2/python/lib/PY4J_LICENSE.txt\n","spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip\n","spark-3.1.2-bin-hadoop3.2/python/docs/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/python_packaging.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/index.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/user_guide/arrow_pandas.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.streaming.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.ss.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.resource.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.mllib.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/index.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.sql.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/reference/pyspark.ml.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3_to_2.4.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.3.0_to_2.3.1_above.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.2_to_2.3.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.4_to_1.5.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_1.0_1.2_to_1.3.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/pyspark_2.4_to_3.0.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/migration_guide/index.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/quickstart.ipynb\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/index.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/getting_started/install.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/development/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/development/testing.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/development/setting_ide.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/development/index.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/development/debugging.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/development/contributing.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/autosummary/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/autosummary/class_with_docs.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_templates/autosummary/class.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/css/\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/css/pyspark.css\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/_static/copybutton.js\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/index.rst\n","spark-3.1.2-bin-hadoop3.2/python/docs/source/conf.py\n","spark-3.1.2-bin-hadoop3.2/python/docs/make.bat\n","spark-3.1.2-bin-hadoop3.2/python/docs/make2.bat\n","spark-3.1.2-bin-hadoop3.2/python/docs/Makefile\n","spark-3.1.2-bin-hadoop3.2/python/README.md\n","spark-3.1.2-bin-hadoop3.2/python/MANIFEST.in\n","spark-3.1.2-bin-hadoop3.2/python/.gitignore\n","spark-3.1.2-bin-hadoop3.2/python/.coveragerc\n","spark-3.1.2-bin-hadoop3.2/python/setup.py\n","spark-3.1.2-bin-hadoop3.2/python/run-tests.py\n","spark-3.1.2-bin-hadoop3.2/python/run-tests-with-coverage\n","spark-3.1.2-bin-hadoop3.2/python/mypy.ini\n","spark-3.1.2-bin-hadoop3.2/python/test_support/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/userlibrary.py\n","spark-3.1.2-bin-hadoop3.2/python/test_support/userlib-0.1.zip\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/text-test.txt\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/streaming/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/streaming/text-test.txt\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people_array_utf16le.json\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people_array.json\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people1.json\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/people.json\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/part-r-00007.gz.parquet\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=9/day=1/.part-r-00007.gz.parquet.crc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/part-r-00005.gz.parquet\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=26/.part-r-00005.gz.parquet.crc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00004.gz.parquet\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/part-r-00002.gz.parquet\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00004.gz.parquet.crc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2015/month=10/day=25/.part-r-00002.gz.parquet.crc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/part-r-00008.gz.parquet\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/year=2014/month=9/day=1/.part-r-00008.gz.parquet.crc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_metadata\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_common_metadata\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/parquet_partitioned/_SUCCESS\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/orc_partitioned/_SUCCESS\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/ages_newlines.csv\n","spark-3.1.2-bin-hadoop3.2/python/test_support/sql/ages.csv\n","spark-3.1.2-bin-hadoop3.2/python/test_support/hello/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/hello/sub_hello/\n","spark-3.1.2-bin-hadoop3.2/python/test_support/hello/sub_hello/sub_hello.txt\n","spark-3.1.2-bin-hadoop3.2/python/test_support/hello/hello.txt\n","spark-3.1.2-bin-hadoop3.2/python/test_support/SimpleHTTPServer.py\n","spark-3.1.2-bin-hadoop3.2/python/test_coverage/\n","spark-3.1.2-bin-hadoop3.2/python/test_coverage/sitecustomize.py\n","spark-3.1.2-bin-hadoop3.2/python/test_coverage/coverage_daemon.py\n","spark-3.1.2-bin-hadoop3.2/python/test_coverage/conf/\n","spark-3.1.2-bin-hadoop3.2/python/test_coverage/conf/spark-defaults.conf\n","spark-3.1.2-bin-hadoop3.2/python/setup.cfg\n","spark-3.1.2-bin-hadoop3.2/python/run-tests\n","spark-3.1.2-bin-hadoop3.2/bin/\n","spark-3.1.2-bin-hadoop3.2/bin/sparkR2.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/sparkR.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/sparkR\n","spark-3.1.2-bin-hadoop3.2/bin/spark-submit2.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-submit.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-submit\n","spark-3.1.2-bin-hadoop3.2/bin/spark-sql2.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-sql.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-sql\n","spark-3.1.2-bin-hadoop3.2/bin/spark-shell2.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-shell.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-shell\n","spark-3.1.2-bin-hadoop3.2/bin/spark-class2.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-class.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/spark-class\n","spark-3.1.2-bin-hadoop3.2/bin/run-example.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/run-example\n","spark-3.1.2-bin-hadoop3.2/bin/pyspark.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/load-spark-env.sh\n","spark-3.1.2-bin-hadoop3.2/bin/load-spark-env.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/find-spark-home.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/find-spark-home\n","spark-3.1.2-bin-hadoop3.2/bin/docker-image-tool.sh\n","spark-3.1.2-bin-hadoop3.2/bin/beeline.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/beeline\n","spark-3.1.2-bin-hadoop3.2/bin/pyspark2.cmd\n","spark-3.1.2-bin-hadoop3.2/bin/pyspark\n","spark-3.1.2-bin-hadoop3.2/README.md\n","spark-3.1.2-bin-hadoop3.2/conf/\n","spark-3.1.2-bin-hadoop3.2/conf/workers.template\n","spark-3.1.2-bin-hadoop3.2/conf/spark-env.sh.template\n","spark-3.1.2-bin-hadoop3.2/conf/spark-defaults.conf.template\n","spark-3.1.2-bin-hadoop3.2/conf/metrics.properties.template\n","spark-3.1.2-bin-hadoop3.2/conf/log4j.properties.template\n","spark-3.1.2-bin-hadoop3.2/conf/fairscheduler.xml.template\n","spark-3.1.2-bin-hadoop3.2/data/\n","spark-3.1.2-bin-hadoop3.2/data/streaming/\n","spark-3.1.2-bin-hadoop3.2/data/streaming/AFINN-111.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/streaming_kmeans_data_test.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_svm_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_multiclass_classification_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_movielens_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_linear_regression_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_libsvm_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_lda_libsvm_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_lda_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_kmeans_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_isotonic_regression_libsvm_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_fpgrowth.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/sample_binary_classification_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/ridge-data/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/ridge-data/lpsa.data\n","spark-3.1.2-bin-hadoop3.2/data/mllib/pic_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/pagerank_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/kmeans_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/iris_libsvm.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/grayscale.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-02/chr30.4.184.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA_alpha_60.png\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=multichannel/date=2018-01/BGRA.png\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP802813.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/DP153539.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-02/54893.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/not-image.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/partitioned/cls=kittens/date=2018-01/29.5.a_b_EGDP022204.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/grayscale.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/multi-channel/BGRA.png\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/license.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/not-image.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/DP802813.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/DP153539.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/54893.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n","spark-3.1.2-bin-hadoop3.2/data/mllib/images/license.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/gmm_data.txt\n","spark-3.1.2-bin-hadoop3.2/data/mllib/als/\n","spark-3.1.2-bin-hadoop3.2/data/mllib/als/test.data\n","spark-3.1.2-bin-hadoop3.2/data/mllib/als/sample_movielens_ratings.txt\n","spark-3.1.2-bin-hadoop3.2/data/graphx/\n","spark-3.1.2-bin-hadoop3.2/data/graphx/users.txt\n","spark-3.1.2-bin-hadoop3.2/data/graphx/followers.txt\n","spark-3.1.2-bin-hadoop3.2/NOTICE\n","spark-3.1.2-bin-hadoop3.2/licenses/\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-zstd.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-zstd-jni.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-xmlenc.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-vis-timeline.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-spire.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-sorttable.js.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-slf4j.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-scopt.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-scala.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-sbt-launch-lib.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-respond.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-reflectasm.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-re2j.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-pyrolite.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-py4j.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-protobuf.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-pmml-model.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-paranamer.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-netlib.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-mustache.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-modernizr.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-minlog.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-matchMedia-polyfill.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-machinist.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-leveldbjni.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-kryo.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jsp-api.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-json-formatter.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jquery.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-join.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jodd.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jline.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jaxb-runtime.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-javolution.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-javax-transaction-transaction-api.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-javassist.html\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-janino.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta.xml.bind-api.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta.activation-api.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta-ws-rs-api\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-jakarta-annotation-api\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-istack-commons-runtime.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-graphlib-dot.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-f2j.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-dnsjava.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-datatables.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-dagre-d3.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-d3.min.js.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-cloudpickle.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-bootstrap.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-automaton.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-arpack.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-antlr.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-JTransforms.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-JLargeArrays.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-CC0.txt\n","spark-3.1.2-bin-hadoop3.2/licenses/LICENSE-AnchorJS.txt\n","spark-3.1.2-bin-hadoop3.2/LICENSE\n","spark-3.1.2-bin-hadoop3.2/examples/\n","spark-3.1.2-bin-hadoop3.2/examples/src/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/users.parquet\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/users.orc\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/users.avro\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/user.avsc\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/people.txt\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/people.json\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/people.csv\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/kv1.txt\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/full_user.avsc\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/employees.json\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/file3.json\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/file1.parquet\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/resources/dir1/dir2/file2.parquet\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/streaming/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/streaming/structured_network_wordcount.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/svmLinear.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/survreg.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/randomForest.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/prefixSpan.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/powerIterationClustering.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/naiveBayes.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/mlp.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/ml.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/logit.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/lm_with_elastic_net.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/lda.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/kstest.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/kmeans.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/isoreg.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/glm.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/gbt.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/gaussianMixture.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/fpm.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/fmRegressor.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/fmClassifier.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/decisionTree.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/bisectingKmeans.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/ml/als.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/dataframe.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/data-manipulation.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/r/RSparkSQLExample.R\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/transitive_closure.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/stateful_network_wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/sql_network_wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/recoverable_network_wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/queue_stream.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/network_wordjoinsentiments.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/network_wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/streaming/hdfs_wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/status_api_demo.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/hive.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/basic.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/arrow.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sql/datasource.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/sort.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/pi.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/parquet_inputformat.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/pagerank.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/word2vec_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/word2vec.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/tf_idf_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/svm_with_sgd_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/svd_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/summary_statistics_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/streaming_linear_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/streaming_k_means_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/stratified_sampling_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/standard_scaler_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/sampled_rdds.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/regression_metrics_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/recommendation_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/ranking_metrics_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/random_rdd_generation.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/random_forest_classification_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/power_iteration_clustering_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/pca_rowmatrix_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/normalizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/naive_bayes_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/multi_label_metrics_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/multi_class_metrics_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/logistic_regression.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/kmeans.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/kernel_density_estimation_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/k_means_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/isotonic_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/hypothesis_testing_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_model.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/gaussian_mixture_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/fpgrowth_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/elementwise_product_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/decision_tree_classification_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/correlations_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/correlations.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/bisecting_k_means_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/mllib/binary_classification_metrics_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/word2vec_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_slicer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_size_hint_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_indexer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/vector_assembler_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/variance_threshold_selector_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/univariate_feature_selector_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/train_validation_split.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/tokenizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/tf_idf_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/summarizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/string_indexer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/stopwords_remover_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/standard_scaler_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/sql_transformer.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/robust_scaler_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/rformula_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/random_forest_regressor_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/random_forest_classifier_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/quantile_discretizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/prefixspan_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/power_iteration_clustering_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/polynomial_expansion_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/pipeline_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/pca_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/onehot_encoder_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/one_vs_rest_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/normalizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/naive_bayes_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/n_gram_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/multilayer_perceptron_classification.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/min_max_scaler_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/min_hash_lsh_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/max_abs_scaler_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/logistic_regression_summary_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/linearsvc.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/lda_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/kmeans_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/isotonic_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/interaction_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/index_to_string_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/imputer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/generalized_linear_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/gaussian_mixture_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/fpgrowth_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/fm_regressor_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/fm_classifier_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/feature_hasher_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/estimator_transformer_param_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/elementwise_product_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_regression_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/decision_tree_classification_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/dct_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/dataframe_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/cross_validator.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/count_vectorizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/correlation_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/chisq_selector_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/chi_square_test_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/bucketizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/bisecting_k_means_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/binarizer_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/als_example.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/ml/aft_survival_regression.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/logistic_regression.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/kmeans.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/avro_inputformat.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/python/als.py\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scripts/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/scripts/getGpusResources.sh\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n","spark-3.1.2-bin-hadoop3.2/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n","spark-3.1.2-bin-hadoop3.2/examples/jars/\n","spark-3.1.2-bin-hadoop3.2/examples/jars/spark-examples_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/examples/jars/scopt_2.12-3.7.1.jar\n","spark-3.1.2-bin-hadoop3.2/kubernetes/\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/worker_memory_check.py\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/python_executable_check.py\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/pyfiles.py\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/py_container_checks.py\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/decommissioning_cleanup.py\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/decommissioning.py\n","spark-3.1.2-bin-hadoop3.2/kubernetes/tests/autoscale.py\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/Dockerfile\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/entrypoint.sh\n","spark-3.1.2-bin-hadoop3.2/kubernetes/dockerfiles/spark/decom.sh\n","spark-3.1.2-bin-hadoop3.2/yarn/\n","spark-3.1.2-bin-hadoop3.2/yarn/spark-3.1.2-yarn-shuffle.jar\n","spark-3.1.2-bin-hadoop3.2/jars/\n","spark-3.1.2-bin-hadoop3.2/jars/zstd-jni-1.4.8-1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/zookeeper-3.4.14.jar\n","spark-3.1.2-bin-hadoop3.2/jars/zjsonpatch-0.3.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/xz-1.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/xbean-asm7-shaded-4.15.jar\n","spark-3.1.2-bin-hadoop3.2/jars/woodstox-core-5.0.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/velocity-1.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/univocity-parsers-2.9.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/transaction-api-1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/token-provider-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/threeten-extra-1.5.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/super-csv-2.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/stream-2.9.6.jar\n","spark-3.1.2-bin-hadoop3.2/jars/stax2-api-3.1.4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/stax-api-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spire_2.12-0.17.0-M1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spire-util_2.12-0.17.0-M1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spire-platform_2.12-0.17.0-M1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spire-macros_2.12-0.17.0-M1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-yarn_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-tags_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-tags_2.12-3.1.2-tests.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-streaming_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-sql_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-sketch_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-repl_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-network-shuffle_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-network-common_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-mllib_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-mllib-local_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-mesos_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-launcher_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-kvstore_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-kubernetes_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-hive_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-hive-thriftserver_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-graphx_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-core_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/spark-catalyst_2.12-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/snappy-java-1.1.8.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/snakeyaml-1.24.jar\n","spark-3.1.2-bin-hadoop3.2/jars/slf4j-log4j12-1.7.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/slf4j-api-1.7.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/shims-0.9.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/shapeless_2.12-2.3.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/scala-xml_2.12-1.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/scala-reflect-2.12.10.jar\n","spark-3.1.2-bin-hadoop3.2/jars/scala-parser-combinators_2.12-1.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/scala-library-2.12.10.jar\n","spark-3.1.2-bin-hadoop3.2/jars/scala-compiler-2.12.10.jar\n","spark-3.1.2-bin-hadoop3.2/jars/scala-collection-compat_2.12-2.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/re2j-1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/pyrolite-4.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/py4j-0.10.9.jar\n","spark-3.1.2-bin-hadoop3.2/jars/protobuf-java-2.5.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/parquet-jackson-1.10.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/parquet-hadoop-1.10.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/parquet-format-2.4.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/parquet-encoding-1.10.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/parquet-common-1.10.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/parquet-column-1.10.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/paranamer-2.8.jar\n","spark-3.1.2-bin-hadoop3.2/jars/osgi-resource-locator-1.0.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/oro-2.0.8.jar\n","spark-3.1.2-bin-hadoop3.2/jars/orc-shims-1.5.12.jar\n","spark-3.1.2-bin-hadoop3.2/jars/orc-mapreduce-1.5.12.jar\n","spark-3.1.2-bin-hadoop3.2/jars/orc-core-1.5.12.jar\n","spark-3.1.2-bin-hadoop3.2/jars/opencsv-2.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/okio-1.14.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/okhttp-3.12.12.jar\n","spark-3.1.2-bin-hadoop3.2/jars/okhttp-2.7.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/objenesis-2.6.jar\n","spark-3.1.2-bin-hadoop3.2/jars/nimbus-jose-jwt-4.41.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/netty-all-4.1.51.Final.jar\n","spark-3.1.2-bin-hadoop3.2/jars/minlog-1.3.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/metrics-jvm-4.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/metrics-json-4.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/metrics-jmx-4.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/metrics-graphite-4.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/metrics-core-4.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/mesos-1.4.0-shaded-protobuf.jar\n","spark-3.1.2-bin-hadoop3.2/jars/macro-compat_2.12-1.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/machinist_2.12-0.6.8.jar\n","spark-3.1.2-bin-hadoop3.2/jars/lz4-java-1.7.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/logging-interceptor-3.12.12.jar\n","spark-3.1.2-bin-hadoop3.2/jars/log4j-1.2.17.jar\n","spark-3.1.2-bin-hadoop3.2/jars/libthrift-0.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/libfb303-0.9.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/leveldbjni-all-1.8.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-storageclass-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-settings-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-scheduling-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-rbac-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-policy-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-networking-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-metrics-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-extensions-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-events-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-discovery-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-core-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-coordination-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-common-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-certificates-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-batch-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-autoscaling-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-apps-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-apiextensions-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-model-admissionregistration-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kubernetes-client-4.12.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kryo-shaded-4.0.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerby-xdr-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerby-util-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerby-pkix-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerby-config-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerby-asn1-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-util-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-simplekdc-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-server-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-identity-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-crypto-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-core-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-common-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-client-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/kerb-admin-1.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jul-to-slf4j-1.7.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jta-1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jsr305-3.0.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jsp-api-2.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/json4s-scalap_2.12-3.7.0-M5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/json4s-jackson_2.12-3.7.0-M5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/json4s-core_2.12-3.7.0-M5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/json4s-ast_2.12-3.7.0-M5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/json-smart-2.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/json-1.8.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jpam-1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jodd-core-3.5.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/joda-time-2.10.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jline-2.14.6.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jersey-server-2.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jersey-media-jaxb-2.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jersey-hk2-2.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jersey-container-servlet-core-2.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jersey-container-servlet-2.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jersey-common-2.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jersey-client-2.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jdo-api-3.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jcl-over-slf4j-1.7.30.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jcip-annotations-1.0-1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jaxb-runtime-2.3.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jaxb-api-2.2.11.jar\n","spark-3.1.2-bin-hadoop3.2/jars/javolution-5.5.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/javax.jdo-3.2.0-m3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/javax.inject-1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/javassist-3.25.0-GA.jar\n","spark-3.1.2-bin-hadoop3.2/jars/janino-3.0.16.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jakarta.xml.bind-api-2.3.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jakarta.ws.rs-api-2.1.6.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jakarta.validation-api-2.0.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jakarta.servlet-api-4.0.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jakarta.inject-2.6.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jakarta.annotation-api-1.3.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jakarta.activation-api-1.2.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-module-scala_2.12-2.10.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-module-paranamer-2.10.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-module-jaxb-annotations-2.10.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-mapper-asl-1.9.13.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-jaxrs-json-provider-2.9.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-jaxrs-base-2.9.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-datatype-jsr310-2.11.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-dataformat-yaml-2.10.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-databind-2.10.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-core-asl-1.9.13.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-core-2.10.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/jackson-annotations-2.10.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/istack-commons-runtime-3.0.8.jar\n","spark-3.1.2-bin-hadoop3.2/jars/httpcore-4.4.12.jar\n","spark-3.1.2-bin-hadoop3.2/jars/httpclient-4.5.6.jar\n","spark-3.1.2-bin-hadoop3.2/jars/htrace-core4-4.1.0-incubating.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hk2-utils-2.6.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hk2-locator-2.6.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hk2-api-2.6.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-vector-code-gen-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-storage-api-2.7.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-shims-scheduler-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-shims-common-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-shims-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-shims-0.23-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-service-rpc-3.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-serde-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-metastore-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-llap-common-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-jdbc-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-exec-2.3.7-core.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-common-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-cli-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hive-beeline-2.3.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-server-web-proxy-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-server-common-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-registry-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-common-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-client-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-yarn-api-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-mapreduce-client-jobclient-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-mapreduce-client-core-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-mapreduce-client-common-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-hdfs-client-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-common-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-client-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-auth-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/hadoop-annotations-3.2.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/guice-servlet-4.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/guice-4.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/guava-14.0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/gson-2.2.4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/geronimo-jcache_1.0_spec-1.0-alpha-1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/generex-1.0.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/flatbuffers-java-1.9.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/ehcache-3.3.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/dnsjava-2.1.7.jar\n","spark-3.1.2-bin-hadoop3.2/jars/derby-10.12.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/datanucleus-rdbms-4.1.19.jar\n","spark-3.1.2-bin-hadoop3.2/jars/datanucleus-core-4.1.17.jar\n","spark-3.1.2-bin-hadoop3.2/jars/datanucleus-api-jdo-4.2.4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/curator-recipes-2.13.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/curator-framework-2.13.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/curator-client-2.13.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/core-1.1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/compress-lzf-1.0.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-text-1.6.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-pool-1.5.4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-net-3.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-math3-3.4.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-logging-1.1.3.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-lang3-3.10.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-lang-2.6.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-io-2.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-httpclient-3.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-dbcp-1.4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-daemon-1.0.13.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-crypto-1.1.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-configuration2-2.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-compress-1.20.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-compiler-3.0.16.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-collections-3.2.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-codec-1.10.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-cli-1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/commons-beanutils-1.9.4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/chill_2.12-0.9.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/chill-java-0.9.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/cats-kernel_2.12-2.0.0-M4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/breeze_2.12-1.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/breeze-macros_2.12-1.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/bonecp-0.8.0.RELEASE.jar\n","spark-3.1.2-bin-hadoop3.2/jars/avro-mapred-1.8.2-hadoop2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/avro-ipc-1.8.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/avro-1.8.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/automaton-1.11-8.jar\n","spark-3.1.2-bin-hadoop3.2/jars/audience-annotations-0.5.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/arrow-vector-2.0.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/arrow-memory-netty-2.0.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/arrow-memory-core-2.0.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/arrow-format-2.0.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/arpack_combined_all-0.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/aopalliance-repackaged-2.6.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/aopalliance-1.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/antlr4-runtime-4.8-1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/antlr-runtime-3.5.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/algebra_2.12-2.0.0-M2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/aircompressor-0.10.jar\n","spark-3.1.2-bin-hadoop3.2/jars/activation-1.1.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/accessors-smart-1.2.jar\n","spark-3.1.2-bin-hadoop3.2/jars/ST4-4.0.4.jar\n","spark-3.1.2-bin-hadoop3.2/jars/RoaringBitmap-0.9.0.jar\n","spark-3.1.2-bin-hadoop3.2/jars/JTransforms-3.1.jar\n","spark-3.1.2-bin-hadoop3.2/jars/JLargeArrays-1.5.jar\n","spark-3.1.2-bin-hadoop3.2/jars/HikariCP-2.5.1.jar\n","spark-3.1.2-bin-hadoop3.2/RELEASE\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxy1SbUZ70cZ","executionInfo":{"status":"ok","timestamp":1634716623781,"user_tz":300,"elapsed":145,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"c4c10e6d-5763-44af-da30-3d16390f8305"},"source":["!ls "],"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":[" Amazon_Responded_Oct05.csv\t\t       spark-3.0.0-bin-hadoop3.2.tgz\n"," BigData_HW2.ipynb\t\t\t       spark-3.0.0-bin-hadoop3.2.tgz.1\n","'Copy of Copy of IDS561_HW2_Final (1).ipynb'   spark-3.1.2-bin-hadoop3.2\n"," find_text.csv\t\t\t\t       spark-3.1.2-bin-hadoop3.2.tgz\n"," HW2room.ipynb\t\t\t\t       spark-3.1.2-bin-hadoop3.2.tgz.1\n","'IDS 561  Homework 2 (1).docx'\t\t       spark-3.1.2-bin-hadoop3.2.tgz.2\n","'IDS561_HW2_Final (1).ipynb'\t\t       task2output.csv\n"," spark-3.0.0-bin-hadoop3.2\t\t       twitterhw2.csv\n"]}]},{"cell_type":"markdown","metadata":{"id":"hTe7J0I-Ozyj"},"source":["# Install findspark - a python library to find Spark"]},{"cell_type":"code","metadata":{"id":"i5w5KMo3O8aW","executionInfo":{"status":"ok","timestamp":1634716627410,"user_tz":300,"elapsed":3631,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["!pip install -q findspark"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ALuz9-YPHNW"},"source":["# Set environment variables\n","Set Java and Spark home based on the location where they are stored"]},{"cell_type":"code","metadata":{"id":"OXCiNFjMNnG4","executionInfo":{"status":"ok","timestamp":1634716824194,"user_tz":300,"elapsed":162,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/drive/My Drive/IDS 561/HW 2/spark-3.1.2-bin-hadoop3.2\""],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"_FY0mR4gKOla","executionInfo":{"status":"ok","timestamp":1634716841324,"user_tz":300,"elapsed":17021,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"2P4gXyFyJpug","executionInfo":{"status":"ok","timestamp":1634716841325,"user_tz":300,"elapsed":21,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/drive/My Drive/IDS 561/HW 2/spark-3.1.2-bin-hadoop3.2\""],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K0ATecsuhluE"},"source":["As we know, in previous versions, sparkContext is the entry point for Spark. As RDD was the main API, it was created and manipulated using context APIs. For every other API, we needed to use a different context.\n","\n","For streamin, we needed streamingContext. For SQL, sqlContext, and for Hive, hiveContext. But as DataSet and DataFrame APIs are becoming new standalone APIs, we need an entry point build for them. So in Spark 2.0, we have a new entry point build for DataSet and DataFrame APIs called as SparkSession."]},{"cell_type":"markdown","metadata":{"id":"HJ5-jo6eNpy4"},"source":["SparkSession is an entry point to underlying PySpark functionality in order to programmatically create PySpark RDD, DataFrame.\n","\n","SparkContext is the entry gate of Apache Spark functionality and the most important step of any Spark driver application is to generate SparkContext which represents the connection to a Spark cluster, and can be used to create RDDs, accumulators and broadcast variables on that cluster.\n","\n","\n","Another important study source: https://dzone.com/articles/introduction-to-spark-session"]},{"cell_type":"markdown","metadata":{"id":"PswYpIzbQNaZ"},"source":["# Creat a local Spark session"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJNU9_TV70nH","executionInfo":{"status":"ok","timestamp":1634716848534,"user_tz":300,"elapsed":7229,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"fc3ad8df-09ce-4b5e-ef14-afce77522a82"},"source":["# https://sparkbyexamples.com/spark/sparksession-explained-with-examples/\n","\n","df = spark.createDataFrame([{\"Google\": \"Colab\",\"Spark\": \"Scala\"} ,{\"Google\": \"Dataproc\",\"Spark\":\"Python\"}])\n","df.show()"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------+------+\n","|  Google| Spark|\n","+--------+------+\n","|   Colab| Scala|\n","|Dataproc|Python|\n","+--------+------+\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"3zOiLdZ970x7"},"source":["##"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dd9Pq3m-YZkK","executionInfo":{"status":"ok","timestamp":1634716850116,"user_tz":300,"elapsed":1591,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"55f0e4c1-80eb-4179-9c34-576aa3f364b3"},"source":["import pyspark\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext\n","import pandas as pd\n","import string\n","import re\n","import nltk\n","\n","#Create the SparkContext\n","sc = SparkContext.getOrCreate()\n","print(\"SparkContext : \", sc)"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["SparkContext :  <SparkContext master=local[*] appName=pyspark-shell>\n"]}]},{"cell_type":"code","metadata":{"id":"Ck2sCw-0PS48","executionInfo":{"status":"ok","timestamp":1634716850627,"user_tz":300,"elapsed":514,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import IntegerType"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"q8MfgpYvSmD6","executionInfo":{"status":"ok","timestamp":1634716852860,"user_tz":300,"elapsed":2234,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":[" #Loading CSV file with spark\n"," amazon = spark.read.csv(\"/content/drive/My Drive/IDS 561/HW 2/Amazon_Responded_Oct05.csv\", header = True)"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"089DheZdO6nT","executionInfo":{"status":"ok","timestamp":1634716853384,"user_tz":300,"elapsed":525,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"9c6ca15f-4cb7-4e0b-8c6c-d8c500714b89"},"source":["amazon_selct = amazon.select('id_str','tweet_created_at','user_verified','favorite_count','retweet_count','text_')\n","amazon_selct.show(5)"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+-------------+--------------+-------------+--------------------+\n","|              id_str|    tweet_created_at|user_verified|favorite_count|retweet_count|               text_|\n","+--------------------+--------------------+-------------+--------------+-------------+--------------------+\n","|'793270689780203520'|Tue Nov 01 01:57:...|        False|             0|            0|@AmazonHelp Can y...|\n","|'793281386912354304'|Tue Nov 01 02:39:...|         True|             0|            0|@SeanEPanjab I'm ...|\n","|'793501578766319616'|Tue Nov 01 17:14:...|        False|             0|            0|@AmazonHelp It wa...|\n","|'793501657346682880'|Tue Nov 01 17:15:...|        False|             0|            0|@AmazonHelp I am ...|\n","|'793502854459879424'|Tue Nov 01 17:19:...|         True|             0|            0|@SeanEPanjab Plea...|\n","+--------------------+--------------------+-------------+--------------+-------------+--------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hurKRhvLO6tp","executionInfo":{"status":"ok","timestamp":1634716853385,"user_tz":300,"elapsed":3,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"68edc66e-4929-486a-ca54-466fa04d3736"},"source":["type(amazon)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pyspark.sql.dataframe.DataFrame"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"r222-qTZYgYF"},"source":["## Task 1"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3OjSMQ8iS5c","executionInfo":{"status":"ok","timestamp":1634716904301,"user_tz":300,"elapsed":322,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"45bc4834-d1d7-47c9-f32a-ec96f7180303"},"source":["##Task1a: Remove the records where “user_verified” is “FALSE”.\n","amazon_selctI = amazon_selct.filter(amazon_selct.user_verified == 'True')\n","amazon_selctI.show(5)"],"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+-------------+--------------+-------------+--------------------+\n","|              id_str|    tweet_created_at|user_verified|favorite_count|retweet_count|               text_|\n","+--------------------+--------------------+-------------+--------------+-------------+--------------------+\n","|'793281386912354304'|Tue Nov 01 02:39:...|         True|             0|            0|@SeanEPanjab I'm ...|\n","|'793502854459879424'|Tue Nov 01 17:19:...|         True|             0|            0|@SeanEPanjab Plea...|\n","|'793504235400884224'|Tue Nov 01 17:25:...|         True|             0|            0|@SeanEPanjab With...|\n","|'793513446633533440'|Tue Nov 01 18:02:...|         True|             0|            0|@SeanEPanjab I'm ...|\n","|'793301295255945216'|Tue Nov 01 03:59:...|         True|             0|            0|@aakashwangnoo Hi...|\n","+--------------------+--------------------+-------------+--------------+-------------+--------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SGP2gEOg5Vx","executionInfo":{"status":"ok","timestamp":1634716910039,"user_tz":300,"elapsed":5614,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"963bd68f-3630-44eb-f539-eb06f14719eb"},"source":["#Task1b_i: Counting the no of TRUE user_verified records\n","amazon_selctI.count()"],"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["171797"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uiJkEYFpBl6","executionInfo":{"status":"ok","timestamp":1634716910466,"user_tz":300,"elapsed":436,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"331b7b99-0430-4222-ddd6-1757d512165b"},"source":["#Task1b_ii: Changing the tweet_created_at to created_date\n","from pyspark.sql.functions import substring\n","amazon_date = amazon_selctI.withColumn('Created_Date', substring('tweet_created_at',5,6))\n","amazon_date.show(5)"],"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+-------------+--------------+-------------+--------------------+------------+\n","|              id_str|    tweet_created_at|user_verified|favorite_count|retweet_count|               text_|Created_Date|\n","+--------------------+--------------------+-------------+--------------+-------------+--------------------+------------+\n","|'793281386912354304'|Tue Nov 01 02:39:...|         True|             0|            0|@SeanEPanjab I'm ...|      Nov 01|\n","|'793502854459879424'|Tue Nov 01 17:19:...|         True|             0|            0|@SeanEPanjab Plea...|      Nov 01|\n","|'793504235400884224'|Tue Nov 01 17:25:...|         True|             0|            0|@SeanEPanjab With...|      Nov 01|\n","|'793513446633533440'|Tue Nov 01 18:02:...|         True|             0|            0|@SeanEPanjab I'm ...|      Nov 01|\n","|'793301295255945216'|Tue Nov 01 03:59:...|         True|             0|            0|@aakashwangnoo Hi...|      Nov 01|\n","+--------------------+--------------------+-------------+--------------+-------------+--------------------+------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDYhuvxxpB2S","executionInfo":{"status":"ok","timestamp":1634716913865,"user_tz":300,"elapsed":3400,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"d158b8ef-08e1-4c6d-cd8f-214da0211b62"},"source":["#Task1b_iii: Counting the number of tweets per each day\n","nooftweetsI = amazon_date.groupBy(amazon_date.Created_Date).count()\n","nooftweetsI.show(5)"],"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+-----+\n","|Created_Date|count|\n","+------------+-----+\n","|      Nov 27|  208|\n","|      Mar 22|  506|\n","|      Apr 16|  632|\n","|      Apr 27|  394|\n","|      May 24|  842|\n","+------------+-----+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1KLyf5Vg5ne","executionInfo":{"status":"ok","timestamp":1634716959951,"user_tz":300,"elapsed":4114,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"788dbc59-9b87-4d3e-aa0c-122c24996659"},"source":["#Dates with highest number of tweets\n","nooftweetsI = nooftweetsI.sort(\"count\", ascending=False)\n","nooftweetsI.show(5)"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+-----+\n","|Created_Date|count|\n","+------------+-----+\n","|      Jan 03| 1536|\n","|      Jan 10| 1508|\n","|      Jan 11| 1496|\n","|      Jan 12| 1410|\n","|      Jan 06| 1364|\n","+------------+-----+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"hVxDHw4Qg6Ct","executionInfo":{"status":"ok","timestamp":1634716962720,"user_tz":300,"elapsed":2778,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["#Task1c:\n","S= amazon_date.filter(amazon_date.Created_Date == \"Jan 03\")\\\n","    .withColumn('totalsum', amazon_date.favorite_count + amazon_date.retweet_count)\\\n","    .select('id_str','totalsum','Created_Date','text_')\\\n","    .sort('totalsum', ascending =False)\\\n","    .take(100)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9VeqaISg6cx","executionInfo":{"status":"ok","timestamp":1634716962720,"user_tz":300,"elapsed":6,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["sample = S\n","prmtxt = []\n","for a in range(len(sample)):\n","  prmtxt.append(sample[a][3])"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"id":"8WVR7mqQXquC","executionInfo":{"status":"ok","timestamp":1634716962720,"user_tz":300,"elapsed":5,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["#Task1c_ii: Cleaning the data\n","def Dataclean(file):\n","    x=file\n","    temp=[]\n","    for a in x:\n","      a.replace(\"'\", \" \")     \n","      a=re.sub(r\"\\@\\w+\",\" \",a)   #removing with @\n","      temp.append(a.translate(str.maketrans(string.punctuation,' '*len(string.punctuation)))) #removing punctuation                   \n","    final=[]\n","    for a in temp:\n","        final.append(\" \".join([w.lower() for w in a.split()  if w.isalpha()]))    \n","    return final"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOmFiZvBQlxP","executionInfo":{"status":"ok","timestamp":1634716963620,"user_tz":300,"elapsed":904,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"4bc48535-68e4-48e4-eb0c-60c43825c3be"},"source":["#Task1c_iii: Word Count\n","S2 = Dataclean(prmtxt)\n","S3 = tuple(S2)\n","rdd = sc.parallelize(S3)\n","counts = rdd.flatMap(lambda line: line.split(\" \")) \\\n","    .map(lambda word: (word, 1)) \\\n","    .reduceByKey(lambda a, b: a + b) \\\n","    .collect()\n","print(counts)"],"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["[('worst', 1), ('no', 5), ('service', 1), ('substantial', 1), ('delivery', 6), ('week', 1), ('we', 46), ('always', 3), ('in', 13), ('confirmation', 1), ('have', 18), ('update', 2), ('tracking', 5), ('fancy', 1), ('already', 1), ('don', 5), ('look', 7), ('pass', 2), ('details', 6), ('https', 44), ('co', 45), ('lil', 1), ('sounds', 1), ('like', 7), ('know', 13), ('playlist', 1), ('this', 27), ('year', 2), ('bv', 2), ('d', 7), ('help', 9), ('when', 5), ('connect', 1), ('us', 28), ('matt', 1), ('friendshipgoals', 1), ('oh', 1), ('i', 23), ('out', 6), ('into', 6), ('options', 3), ('hear', 4), ('as', 4), ('let', 7), ('doesn', 5), ('arrive', 6), ('tomorrow', 2), ('an', 8), ('ar', 3), ('apologies', 2), ('incorrect', 1), ('item', 5), ('using', 2), ('above', 2), ('do', 4), ('further', 5), ('concerns', 1), ('ca', 1), ('thanks', 11), ('shout', 1), ('looking', 2), ('improve', 1), ('share', 1), ('specific', 1), ('feedback', 7), ('via', 4), ('form', 1), ('sj', 6), ('delay', 1), ('indicate', 1), ('new', 3), ('check', 1), ('updates', 3), ('amazon', 7), ('is', 13), ('est', 1), ('at', 6), ('checkout', 1), ('late', 2), ('cyqkduakwj', 2), ('af', 2), ('s', 7), ('now', 3), ('identify', 1), ('flagging', 1), ('reviewed', 1), ('earliest', 1), ('account', 2), ('but', 3), ('refund', 2), ('en', 3), ('was', 5), ('sent', 1), ('fulfilled', 1), ('third', 2), ('site', 3), ('doug', 1), ('returns', 1), ('items', 1), ('online', 1), ('more', 3), ('seeing', 1), ('advise', 1), ('there', 2), ('getting', 2), ('below', 1), ('pk', 1), ('truly', 2), ('only', 1), ('able', 3), ('end', 1), ('of', 3), ('enjoying', 2), ('collection', 1), ('keeps', 1), ('binge', 1), ('watch', 1), ('feel', 4), ('athena', 1), ('rather', 2), ('delivering', 2), ('things', 1), ('than', 1), ('cold', 1), ('medicine', 1), ('am', 1), ('customer', 2), ('sr', 5), ('card', 2), ('typically', 3), ('process', 1), ('business', 2), ('days', 1), ('requested', 2), ('ve', 2), ('connecting', 1), ('leave', 3), ('way', 2), ('ab', 1), ('waiting', 1), ('carriers', 1), ('until', 2), ('shipment', 1), ('transit', 1), ('destination', 1), ('edd', 1), ('promised', 1), ('inconvenience', 2), ('caused', 1), ('alerts', 2), ('forwarded', 1), ('relevant', 1), ('department', 2), ('jj', 1), ('trouble', 3), ('tried', 1), ('unlinking', 1), ('linking', 1), ('cs', 1), ('sound', 1), ('right', 1), ('support', 3), ('availability', 1), ('payment', 2), ('couriers', 1), ('make', 2), ('sure', 4), ('regret', 1), ('work', 1), ('these', 4), ('instances', 1), ('never', 1), ('happen', 1), ('bringing', 2), ('page', 1), ('investigate', 1), ('hb', 4), ('receiver', 1), ('stopped', 1), ('working', 1), ('very', 1), ('interest', 2), ('phone', 3), ('longer', 1), ('visit', 2), ('mobile', 1), ('browser', 1), ('where', 2), ('newest', 1), ('following', 2), ('steps', 4), ('sb', 1), ('understand', 1), ('showing', 1), ('allow', 1), ('free', 2), ('chat', 2), ('assistance', 1), ('team', 2), ('send', 1), ('use', 1), ('desktop', 1), ('cd', 1), ('concern', 1), ('filled', 1), ('mm', 1), ('didn', 1), ('ask', 1), ('are', 2), ('quality', 1), ('shirt', 1), ('contacted', 2), ('them', 1), ('ra', 1), ('delighted', 1), ('appreciation', 1), ('stayhealthy', 1), ('friendly', 1), ('love', 1), ('certainly', 1), ('try', 3), ('danny', 1), ('may', 2), ('open', 1), ('settings', 1), ('kd', 1), ('tm', 2), ('john', 1), ('recommend', 1), ('website', 1), ('social', 1), ('gl', 3), ('confirm', 1), ('questions', 2), ('li', 1), ('start', 1), ('puppy', 1), ('pretty', 1), ('cute', 1), ('sharing', 1), ('becoming', 1), ('joke', 1), ('speak', 1), ('trying', 1), ('put', 1), ('cutting', 1), ('eligible', 1), ('edit', 1), ('orders', 1), ('letting', 2), ('acct', 1), ('books', 1), ('select', 1), ('vihgdspeur', 1), ('goes', 1), ('mark', 1), ('anything', 1), ('night', 1), ('close', 1), ('click', 1), ('quickly', 1), ('regarding', 1), ('issues', 1), ('hasn', 1), ('qualify', 1), ('claim', 1), ('give', 1), ('other', 1), ('reported', 1), ('looked', 1), ('shopping', 4), ('experience', 9), ('reply', 2), ('to', 65), ('complaints', 1), ('for', 50), ('post', 1), ('guarantee', 3), ('date', 5), ('aim', 2), ('deliver', 4), ('by', 8), ('the', 65), ('given', 1), ('your', 34), ('email', 3), ('missed', 1), ('that', 20), ('any', 8), ('nf', 1), ('you', 64), ('so', 18), ('knooow', 1), ('ep', 2), ('awww', 1), ('happy', 5), ('birthday', 2), ('t', 61), ('a', 25), ('day', 4), ('over', 1), ('on', 14), ('here', 33), ('surprise', 1), ('rs', 2), ('what', 6), ('add', 1), ('halloween', 1), ('hi', 14), ('moment', 1), ('please', 20), ('with', 6), ('yp', 2), ('friendsforever', 1), ('jo', 6), ('m', 13), ('sorry', 21), ('reach', 3), ('can', 28), ('haplpmlfhn', 5), ('contact', 11), ('and', 17), ('ll', 9), ('it', 19), ('keep', 7), ('posted', 6), ('if', 22), ('they', 1), ('direct', 1), ('number', 1), ('bad', 2), ('request', 4), ('return', 5), ('link', 6), ('provided', 3), ('sh', 6), ('hey', 9), ('glad', 3), ('issue', 2), ('has', 3), ('been', 2), ('resolved', 1), ('re', 10), ('pls', 3), ('did', 1), ('e', 2), ('mail', 2), ('order', 10), ('need', 4), ('download', 2), ('video', 2), ('app', 6), ('which', 1), ('separate', 1), ('from', 2), ('how', 3), ('report', 2), ('not', 4), ('cl', 2), ('up', 2), ('ak', 1), ('access', 3), ('through', 3), ('twitter', 2), ('review', 4), ('wrong', 2), ('case', 2), ('being', 1), ('or', 4), ('party', 2), ('seller', 5), ('our', 10), ('arrange', 1), ('most', 3), ('see', 3), ('info', 4), ('cj', 2), ('aren', 1), ('contacting', 1), ('error', 1), ('while', 2), ('redeeming', 1), ('rw', 1), ('directly', 1), ('want', 2), ('customers', 1), ('be', 8), ('aw', 1), ('prime', 1), ('better', 3), ('stay', 1), ('tuned', 1), ('soon', 2), ('much', 2), ('fun', 1), ('features', 1), ('refunds', 1), ('credit', 1), ('within', 1), ('received', 1), ('shall', 1), ('about', 4), ('skgzkjcdng', 1), ('went', 1), ('could', 1), ('elaborate', 1), ('arrived', 3), ('exchange', 2), ('find', 2), ('damaged', 1), ('replacement', 3), ('nxgaalzhis', 1), ('will', 6), ('pm', 1), ('then', 3), ('wj', 4), ('scan', 3), ('indicates', 1), ('should', 2), ('manage', 2), ('text', 1), ('spotify', 1), ('alexa', 1), ('time', 3), ('unable', 2), ('mpos', 1), ('device', 1), ('cod', 1), ('vs', 1), ('create', 1), ('stock', 2), ('same', 1), ('place', 1), ('its', 1), ('isn', 2), ('repeated', 1), ('attention', 2), ('list', 1), ('me', 3), ('next', 1), ('thank', 1), ('windows', 1), ('application', 1), ('available', 2), ('encourage', 1), ('cancel', 1), ('membership', 1), ('hope', 3), ('helps', 3), ('concerned', 1), ('expected', 1), ('status', 2), ('some', 3), ('real', 1), ('td', 1), ('kindle', 3), ('teams', 2), ('assist', 2), ('hg', 2), ('ctrl', 1), ('f', 1), ('address', 1), ('get', 3), ('kindly', 1), ('drop', 1), ('shared', 1), ('earlier', 2), ('asked', 1), ('receive', 1), ('reviews', 1), ('written', 1), ('w', 2), ('purchased', 1), ('product', 1), ('happynewyear', 1), ('packages', 1), ('ja', 3), ('shoutout', 1), ('knowing', 1), ('helped', 1), ('updated', 1), ('sorted', 2), ('ae', 3), ('menu', 1), ('packaging', 1), ('submit', 1), ('amp', 1), ('picture', 1), ('checking', 1), ('media', 1), ('back', 1), ('frustrating', 1), ('reading', 1), ('lg', 1), ('paw', 1), ('supervisor', 1), ('colleagues', 1), ('off', 1), ('still', 1), ('modify', 1), ('method', 1), ('great', 2), ('evening', 1), ('else', 1), ('yourself', 1), ('recent', 1), ('location', 1), ('cleared', 1), ('customs', 1), ('view', 1), ('were', 1), ('ship', 1), ('fitbit', 1), ('arrives', 1), ('information', 1), ('rm', 1), ('z', 1), ('found', 1), ('had', 1), ('internally', 1), ('patience', 1), ('hk', 1)]\n"]}]},{"cell_type":"code","metadata":{"id":"tE3yR2nCQ9Uu","executionInfo":{"status":"ok","timestamp":1634716963756,"user_tz":300,"elapsed":137,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":["final = pd.DataFrame(counts,columns = ['word','frequency'])\n","final.to_csv ('/content/drive/My Drive/IDS 561/HW 2/twitterhw2.csv', index = False, header=True)"],"execution_count":55,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kRK5iwK1YBP2"},"source":["##Task 2"]},{"cell_type":"code","metadata":{"id":"fq5XVq1og62f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634716964398,"user_tz":300,"elapsed":645,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"ddfe3af4-3e9b-4be2-9f42-2e4e96c39e7f"},"source":[" #Loading CSV file with spark\n"," find_text_data = spark.read.csv('/content/drive/My Drive/IDS 561/HW 2/find_text.csv', header = True)\n"," find_text_data.show(5)"],"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+----+\n","|              id_str|text|\n","+--------------------+----+\n","|'793270689780203520'|null|\n","|'793281386912354304'|null|\n","|'793299404975247360'|null|\n","|'793301295255945216'|null|\n","|'793315815411978240'|null|\n","+--------------------+----+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"id":"qsalwtYl709L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634716965938,"user_tz":300,"elapsed":1542,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"d183a008-c76c-4e29-b13c-39724491a94c"},"source":["#Converting df to temptable and joining them\n","dtfm1 = amazon\n","dtfm2 = find_text_data\n","dtfm1.registerTempTable(\"tempamazon\")\n","dtfm2.registerTempTable(\"tempfindtext\")\n","findDF_final = spark.sql('select tft.id_str as TweetID, ta.text_ as text  from tempamazon ta join tempfindtext tft on ta.id_str = tft.id_str')\n","findDF_final.show(5)"],"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+\n","|             TweetID|                text|\n","+--------------------+--------------------+\n","|'793270689780203520'|@AmazonHelp Can y...|\n","|'793281386912354304'|@SeanEPanjab I'm ...|\n","|'793501578766319616'|@AmazonHelp It wa...|\n","|'793501657346682880'|@AmazonHelp I am ...|\n","|'793502854459879424'|@SeanEPanjab Plea...|\n","+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":329},"id":"kZK6UsH471IK","executionInfo":{"status":"error","timestamp":1634716966502,"user_tz":300,"elapsed":568,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"91f4321d-5a3c-424a-85ff-2143746ea874"},"source":["#Writing results to csv file\n","findDF_final.write.csv('/content/drive/My Drive/IDS 561/HW 2/task2output.csv')"],"execution_count":58,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-2dfabac5a328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Writing results to csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfindDF_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/IDS 561/HW 2/task2output.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/My Drive/IDS 561/HW 2/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0morc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitionBy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/IDS 561/HW 2/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/IDS 561/HW 2/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: path file:/content/drive/My Drive/IDS 561/HW 2/task2output.csv already exists."]}]},{"cell_type":"code","metadata":{"id":"EdWGLMYy71ao","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634716987277,"user_tz":300,"elapsed":2436,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}},"outputId":"f1ce64e6-eda8-4070-dfb8-dd01003039e7"},"source":["findDF_final.count()"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"text/plain":["53927"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"dxeN_MKH71kS","executionInfo":{"status":"aborted","timestamp":1634716966376,"user_tz":300,"elapsed":7,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdLOHobK71tn","executionInfo":{"status":"aborted","timestamp":1634716966376,"user_tz":300,"elapsed":7,"user":{"displayName":"Sai Nischith Vangala","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04182288516661653496"}}},"source":[""],"execution_count":null,"outputs":[]}]}